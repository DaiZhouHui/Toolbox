#!/usr/bin/env python3
"""
Toolbox ä¸»ç”Ÿæˆè„šæœ¬ - è‡ªåŠ¨åˆ†æGitHubä»“åº“å¹¶ç”ŸæˆREADMEä»ªè¡¨æ¿
ä½œè€…: DaiZhouHui
åŠŸèƒ½: è‡ªåŠ¨ä»æŒ‡å®šçš„GitHubä»“åº“æå–ä¿¡æ¯ï¼Œç”Ÿæˆç»Ÿä¸€çš„Toolboxé¡µé¢
"""
import os
import sys
import time  # åœ¨æ–‡ä»¶å¼€å¤´çš„å¯¼å…¥éƒ¨åˆ†æ·»åŠ è¿™è¡Œ
import json  # ç¡®ä¿å¯¼å…¥äº†jsonæ¨¡å—
import requests
import json
import base64
import binascii  # <-- æ–°å¢è¿™è¡Œ
import re
from datetime import datetime
from typing import List, Dict, Optional, Any
# ========== é…ç½®éƒ¨åˆ† ==========
# ä»ç¯å¢ƒå˜é‡è¯»å–GitHubä»¤ç‰Œå’Œç”¨æˆ·å
from dotenv import load_dotenv
load_dotenv()  # åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
USERNAME = os.getenv('GITHUB_USERNAME', 'DaiZhouHui')
# 
# ========== ä»congfig.jsoné…ç½®æ–‡ä»¶è¯»å–è¦åˆ†æçš„ä»“åº“åˆ—è¡¨ ==========
CONFIG_FILE = 'config.json'
try:
    with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
        config = json.load(f)
    USERNAME = config.get('github_username', 'DaiZhouHui')
    REPO_LIST = config.get('repositories', [])
    print(f"âœ… å·²ä» {CONFIG_FILE} åŠ è½½é…ç½®ã€‚")
except FileNotFoundError:
    print(f"âš ï¸  æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ {CONFIG_FILE}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
    USERNAME = 'DaiZhouHui'
    REPO_LIST = ["NodeWeb", "CustomNode", "50DayChallenge"]
# ====================================

# å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»¤ç‰Œï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
if not GITHUB_TOKEN:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° GitHub Tokenã€‚")
    print("è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
    print("  1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶")
    print("  2. åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : GITHUB_TOKEN=ä½ çš„GitHubä»¤ç‰Œ")
    print("  3. ç¡®ä¿ .env åœ¨ .gitignore ä¸­ï¼Œä¸ä¼šè¢«æäº¤")
    print("")
    print("å¦‚ä½•è·å–GitHubä»¤ç‰Œ:")
    print("  1. è®¿é—® https://github.com/settings/tokens")
    print("  2. ç‚¹å‡» Generate new token (classic)")
    print("  3. å‹¾é€‰ 'repo' æƒé™")
    print("  4. ç”Ÿæˆå¹¶å¤åˆ¶ä»¤ç‰Œ")
    sys.exit(1)
# ========== GitHub API å‡½æ•° ==========

def call_github_api(endpoint: str, retries: int = 2) -> Optional[Dict[str, Any]]:  # æ·»åŠ é‡è¯•å‚æ•°
    """
    è°ƒç”¨GitHub APIï¼Œå¢åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
    """
    url = f"https://api.github.com{endpoint}"
    headers = {
        'Authorization': f'token {GITHUB_TOKEN}',
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'Toolbox-Auto-Generator'
    }

    # ==== ã€ä¿®å¤ã€‘å¸¦æœ‰æ•ˆæ€§æ£€æŸ¥çš„ç¼“å­˜è¯»å– ====
    safe_endpoint = endpoint.replace('/', '_').replace(':', '_')
    cache_dir = "api_cache"
    cache_file = os.path.join(cache_dir, f"cache_{safe_endpoint}.json")
    
    # å¦‚æœç¼“å­˜æ–‡ä»¶å­˜åœ¨ä¸”éç©ºï¼Œå°è¯•è¯»å–
    if os.path.exists(cache_file) and os.path.getsize(cache_file) > 0:
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cached_data = json.load(f)
            # å…³é”®æ£€æŸ¥ï¼šç¡®ä¿ç¼“å­˜çš„æ•°æ®æ˜¯æœ‰æ•ˆçš„å­—å…¸ï¼Œä¸æ˜¯Noneæˆ–ç©º
            if isinstance(cached_data, dict) and cached_data:
                print(f"  ğŸ’¾ ä»ç¼“å­˜åŠ è½½: {endpoint}")
                return cached_data
            else:
                print(f"  âš ï¸  ç¼“å­˜æ•°æ®æ— æ•ˆï¼Œé‡æ–°è¯·æ±‚: {endpoint}")
        except (json.JSONDecodeError, IOError) as e:
            print(f"  âš ï¸  ç¼“å­˜æ–‡ä»¶æŸåï¼Œé‡æ–°è¯·æ±‚: {endpoint}")
    # ======================================
    
    for attempt in range(retries + 1):
        try:
            # å°†è¶…æ—¶æ—¶é—´ä»10ç§’å¢åŠ åˆ°30ç§’
            response = requests.get(url, headers=headers, timeout=30)
            
            # æ£€æŸ¥HTTPçŠ¶æ€
            if response.status_code == 403:
                print(f"  âš ï¸ APIé™åˆ¶æˆ–ä»¤ç‰Œæƒé™ä¸è¶³: {response.status_code}")
                break
            elif response.status_code == 404:
                print(f"  âš ï¸ ä»“åº“ä¸å­˜åœ¨: {endpoint}")
                break
            elif response.status_code != 200:
                print(f"  âš ï¸ APIè¯·æ±‚å¤±è´¥ ({endpoint}): HTTP {response.status_code}")
                if attempt < retries:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿ç­‰å¾…
                    print(f"    ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                break
                
            # è¯·æ±‚æˆåŠŸï¼Œè§£ææ•°æ®
            data = response.json()
            
            # ==== ã€ä¿®å¤ã€‘ä»…å½“æ•°æ®æœ‰æ•ˆæ—¶æ‰å†™å…¥ç¼“å­˜ ====
            if data is not None:  # å…³é”®åˆ¤æ–­ï¼šç¡®ä¿ä¸æ˜¯None
                try:
                    # å°† endpoint è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å
                    safe_endpoint = endpoint.replace('/', '_').replace(':', '_')
                    cache_file = os.path.join("api_cache", f"cache_{safe_endpoint}.json")
                    
                    # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
                    os.makedirs("api_cache", exist_ok=True)
                    
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                except Exception as e:
                    print(f"  âš ï¸  ç¼“å­˜å†™å…¥å¤±è´¥ï¼ˆä¸å½±å“è¿è¡Œï¼‰: {e}")
            # ==========================================
            
            return data
            
        except requests.exceptions.Timeout:
            print(f"  âš ï¸ APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt+1}/{retries+1}): {endpoint}")
            if attempt < retries:
                wait_time = 3 * (attempt + 1)  # ç­‰å¾…3ç§’ã€6ç§’
                print(f"    ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
                continue
            else:
                print(f"  âŒ é‡è¯•å¤šæ¬¡åä»å¤±è´¥: {endpoint}")
                return None
        except requests.exceptions.RequestException as e:
            print(f"  âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥ (å°è¯• {attempt+1}/{retries+1}): {e}")
            if attempt < retries:
                time.sleep(3)
                continue
            return None
        except json.JSONDecodeError as e:
            print(f"  âš ï¸ JSONè§£æå¤±è´¥ ({endpoint}): {e}")
            return None
    
    return None
def get_repository_info(owner: str, repo_name: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯
    """
    return call_github_api(f"/repos/{owner}/{repo_name}")
def get_repository_readme(owner: str, repo_name: str) -> str:
    """
    è·å–ä»“åº“çš„READMEå†…å®¹
    """
    data = call_github_api(f"/repos/{owner}/{repo_name}/readme")
    
    if data and data.get('encoding') == 'base64':
        try:
            content = base64.b64decode(data['content']).decode('utf-8', errors='ignore')
            return content
        except (binascii.Error, UnicodeDecodeError) as e:  # <-- ä¿®æ”¹è¿™é‡Œ
            print(f"  âš ï¸ READMEè§£ç å¤±è´¥: {e}")
            return ""
    
    return ""
def get_repository_languages(owner: str, repo_name: str) -> Dict[str, int]:
    """
    è·å–ä»“åº“ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
    """
    data = call_github_api(f"/repos/{owner}/{repo_name}/languages")
    return data if data else {}
# ========== READMEåˆ†æå‡½æ•° ==========
def extract_description_from_readme(readme_content: str, repo_name: str) -> str:
    """
    ä»READMEå†…å®¹ä¸­æ™ºèƒ½æå–é¡¹ç›®æè¿°
    """
    if not readme_content or not readme_content.strip():
        return f"{repo_name} - ä¸€ä¸ªå®ç”¨çš„å¼€å‘å·¥å…·é¡¹ç›®"
    
    lines = readme_content.split('\n')
    description_candidates = []
    
    # ç¬¬ä¸€éï¼šå¯»æ‰¾æ˜æ˜¾çš„æè¿°æ®µè½
    for i, line in enumerate(lines):
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œå’Œæ˜æ˜¾çš„éæè¿°è¡Œ
        if not line:
            continue
        if line.startswith(('#', '!', '[', '```', '<!--', '---', '|', '>', '- ', '* ', '1.')):
            continue
        if len(line) < 25:  # å¤ªçŸ­çš„å¯èƒ½ä¸æ˜¯æè¿°
            continue
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æè¿°æ€§å…³é”®è¯
        descriptive_keywords = ['æ˜¯ä¸€ä¸ª', 'ç”¨äº', 'æä¾›', 'æ”¯æŒ', 'åŸºäº', 'å®ç°', 'å¯ä»¥å¸®åŠ©', 'ç”¨äº']
        if any(keyword in line for keyword in descriptive_keywords):
            description_candidates.append(line)
            if len(description_candidates) >= 2:
                break
    
    # ç¬¬äºŒéï¼šå¦‚æœæ²¡æ‰¾åˆ°ï¼Œå–ç¬¬ä¸€æ®µéç©ºæ–‡æœ¬
    if not description_candidates:
        for line in lines:
            line = line.strip()
            if line and not line.startswith(('#', '!', '[', '```', '<!--')):
                if 30 < len(line) < 200:
                    description_candidates.append(line)
                    break
    
    # å¤„ç†æ‰¾åˆ°çš„æè¿°
    if description_candidates:
        description = description_candidates[0]
        
        # æ¸…ç†Markdownæ ¼å¼
        description = re.sub(r'!\[.*?\]\(.*?\)', '', description)  # ç§»é™¤å›¾ç‰‡
        description = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', description)  # ç§»é™¤é“¾æ¥ä¿ç•™æ–‡æœ¬
        description = re.sub(r'`([^`]+)`', r'\1', description)  # ç§»é™¤ä»£ç æ ‡è®°
        description = re.sub(r'\*\*([^*]+)\*\*', r'\1', description)  # ç§»é™¤ç²—ä½“
        description = re.sub(r'\*([^*]+)\*', r'\1', description)  # ç§»é™¤æ–œä½“
        
        # é™åˆ¶é•¿åº¦
        if len(description) > 180:
            description = description[:177] + '...'
        
        return description
    
    # å¤‡ç”¨æ–¹æ¡ˆï¼šè¿”å›ç®€åŒ–çš„æè¿°
    return f"{repo_name} é¡¹ç›®ï¼Œæä¾›å®ç”¨çš„åŠŸèƒ½å’Œå·¥å…·"
def analyze_repository(repo_name: str) -> Optional[Dict[str, Any]]:
    """
    åˆ†æå•ä¸ªä»“åº“ï¼ˆè¶…çº§é˜²å¾¡ç‰ˆæœ¬ï¼‰
    æ ¸å¿ƒåŸåˆ™ï¼šä»»ä½•ä¸€æ­¥å¤±è´¥éƒ½ä¸å´©æºƒï¼Œä½¿ç”¨é»˜è®¤å€¼ç»§ç»­ã€‚
    """
    print(f"ğŸ” åˆ†æä»“åº“: {repo_name}")
    
    # 1. è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯ - è¿™æ˜¯æœ€å¯èƒ½å¤±è´¥çš„æ ¹æº
    repo_data = None
    try:
        repo_data = get_repository_info(USERNAME, repo_name)
    except Exception as e:
        print(f"  âš ï¸  è°ƒç”¨get_repository_infoæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
    
    # ========== æ ¸å¿ƒé˜²å¾¡ï¼šä¸¥æ ¼æ£€æŸ¥ repo_data ==========
    if repo_data is None:
        print(f"  âŒ è‡´å‘½é”™è¯¯ï¼šæ— æ³•è·å–ä»“åº“ '{repo_name}' çš„ä»»ä½•ä¿¡æ¯ã€‚å°†è·³è¿‡æ­¤ä»“åº“ã€‚")
        return None
    
    if not isinstance(repo_data, dict):
        print(f"  âš ï¸  è­¦å‘Šï¼šä»“åº“ '{repo_name}' çš„æ•°æ®ç±»å‹ä¸æ˜¯å­—å…¸ ({type(repo_data)})ã€‚å°†ä½¿ç”¨ç©ºå­—å…¸ã€‚")
        repo_data = {}
    # ==================================================
    
    # 2. æ™ºèƒ½æå–æè¿°ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼Œæ¯ä¸€æ­¥éƒ½åŠ ä¿æŠ¤ï¼‰
    final_description = f"{repo_name} - ä¸€ä¸ªå¼€å‘é¡¹ç›®"  # æœ€ç»ˆå…œåº•æè¿°
    
    # å°è¯•è·å–GitHubå®˜æ–¹æè¿°
    gh_description = ""
    try:
        gh_description = repo_data.get('description', '')
        if gh_description and isinstance(gh_description, str):
            gh_description = gh_description.strip()
    except Exception:
        gh_description = ""
    
    # å¦‚æœå®˜æ–¹æè¿°æœ‰æ•ˆï¼Œç›´æ¥ä½¿ç”¨
    if gh_description:
        final_description = gh_description
    else:
        # å¦åˆ™ï¼Œå°è¯•é€šè¿‡READMEæå–
        print(f"  ğŸ“„ å°è¯•ä»READMEæå–æè¿°...")
        readme_content = ""
        try:
            readme_content = get_repository_readme(USERNAME, repo_name)
        except Exception as e:
            print(f"    âš ï¸  è·å–READMEå¤±è´¥: {e}")
        
        if readme_content:
            try:
                extracted_desc = extract_description_from_readme(readme_content, repo_name)
                if extracted_desc and extracted_desc != f"{repo_name} - ä¸€ä¸ªå®ç”¨çš„å¼€å‘å·¥å…·é¡¹ç›®":
                    final_description = extracted_desc
            except Exception as e:
                print(f"    âš ï¸  åˆ†æREADMEå¤±è´¥: {e}")
    
    # 3. å®‰å…¨åœ°æå–æ‰€æœ‰å…¶ä»–ä¿¡æ¯ï¼Œå¹¶ä¸ºä»»ä½•å¯èƒ½çš„å¼‚å¸¸æä¾›é»˜è®¤å€¼
    try:
        main_language = repo_data.get('language')
        if not main_language or not isinstance(main_language, str):
            main_language = 'å¤šç§è¯­è¨€'
    except Exception:
        main_language = 'å¤šç§è¯­è¨€'
    
    try:
        languages_list = []
        # æ³¨æ„ï¼šget_repository_languages å‡½æ•°ä¹Ÿå¯èƒ½è¿”å›Noneæˆ–å¤±è´¥
        langs_data = get_repository_languages(USERNAME, repo_name)
        if isinstance(langs_data, dict):
            languages_list = list(langs_data.keys())[:3]
    except Exception:
        languages_list = []
    
    # 4. æ„å»ºæœ€ç»ˆçš„ä¿¡æ¯å­—å…¸ï¼ˆæ‰€æœ‰å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼‰
    repository_info = {
        # åŸºæœ¬ä¿¡æ¯ï¼ˆæœ‰ä¸¥æ ¼æ£€æŸ¥ï¼Œç›¸å¯¹å®‰å…¨ï¼‰
        'name': repo_name,
        'url': repo_data.get('html_url', f'https://github.com/{USERNAME}/{repo_name}'),
        
        # æè¿°ä¿¡æ¯ï¼ˆç»è¿‡å¤šé‡ä¿æŠ¤ï¼‰
        'official_description': gh_description,  # åŸå§‹GitHubæè¿°ï¼Œå¯èƒ½ä¸ºç©º
        'extracted_description': final_description,
        'final_description': final_description,
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆæä¾›é»˜è®¤å€¼0ï¼‰
        'stars': repo_data.get('stargazers_count', 0) if isinstance(repo_data.get('stargazers_count'), (int, float)) else 0,
        'forks': repo_data.get('forks_count', 0) if isinstance(repo_data.get('forks_count'), (int, float)) else 0,
        'watchers': repo_data.get('watchers_count', 0) if isinstance(repo_data.get('watchers_count'), (int, float)) else 0,
        'open_issues': repo_data.get('open_issues_count', 0) if isinstance(repo_data.get('open_issues_count'), (int, float)) else 0,
        
        # æ—¶é—´ä¿¡æ¯ï¼ˆå®‰å…¨æå–ï¼Œæä¾›ç©ºå­—ç¬¦ä¸²é»˜è®¤å€¼ï¼‰
        'created_at': (repo_data.get('created_at', '')[:10] if isinstance(repo_data.get('created_at'), str) else ''),
        'updated_at': (repo_data.get('updated_at', '')[:10] if isinstance(repo_data.get('updated_at'), str) else ''),
        'pushed_at': (repo_data.get('pushed_at', '')[:10] if isinstance(repo_data.get('pushed_at'), str) else ''),
        
        # æŠ€æœ¯ä¿¡æ¯
        'language': main_language,
        'languages': languages_list,
        'topics': repo_data.get('topics', []) if isinstance(repo_data.get('topics'), list) else [],
        'license': (repo_data.get('license', {}).get('name') 
                    if repo_data.get('license') and isinstance(repo_data.get('license'), dict) 
                    else None),
        
        # åŠŸèƒ½ç‰¹æ€§
        'has_wiki': repo_data.get('has_wiki', False) if isinstance(repo_data.get('has_wiki'), bool) else False,
        'has_pages': repo_data.get('has_pages', False) if isinstance(repo_data.get('has_pages'), bool) else False,
        'has_projects': repo_data.get('has_projects', False) if isinstance(repo_data.get('has_projects'), bool) else False,
        'has_downloads': repo_data.get('has_downloads', True) if isinstance(repo_data.get('has_downloads'), bool) else True,
        
        # çŠ¶æ€ä¿¡æ¯
        'archived': repo_data.get('archived', False) if isinstance(repo_data.get('archived'), bool) else False,
        'disabled': repo_data.get('disabled', False) if isinstance(repo_data.get('disabled'), bool) else False,
        'private': repo_data.get('private', False) if isinstance(repo_data.get('private'), bool) else False,
    }
    
    print(f"  âœ… æˆåŠŸåˆ†æ: {repo_name} (â­ {repository_info['stars']})")
    return repository_info
# ========== READMEç”Ÿæˆå‡½æ•° ==========
def generate_badge(label: str, value: Any, color: str = "blue") -> str:
    """
    ç”ŸæˆShields.ioå¾½ç« 
    """
    value_str = str(value).replace('-', '--').replace('_', '__')
    label_str = str(label).replace('-', '--').replace('_', '__')
    return f"![{label}](https://img.shields.io/badge/{label_str}-{value_str}-{color})"
def generate_repository_card(repo_info: Dict[str, Any]) -> str:
    """
    ä¸ºå•ä¸ªä»“åº“ç”ŸæˆMarkdownå¡ç‰‡
    """
    card = f"""
### ğŸ—ƒï¸ [{repo_info['name']}]({repo_info['url']})
{repo_info['final_description']}
**ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:**
- â­ æ˜Ÿæ ‡: **{repo_info['stars']}** | ğŸ´ Fork: **{repo_info['forks']}**
- ğŸ“… æ›´æ–°: `{repo_info['updated_at']}` | ğŸ› é—®é¢˜: {repo_info['open_issues']}
- ğŸ”§ è¯­è¨€: `{repo_info['language']}` | ğŸ“š Wiki: {'âœ…' if repo_info['has_wiki'] else 'âŒ'}
"""
    
    # æ·»åŠ ä¸»é¢˜æ ‡ç­¾
    if repo_info['topics']:
        topics_str = ' '.join([f'`{topic}`' for topic in repo_info['topics'][:5]])
        card += f"**ğŸ·ï¸ ä¸»é¢˜æ ‡ç­¾:** {topics_str}\n\n"
    
    # æ·»åŠ è®¸å¯è¯ä¿¡æ¯
    if repo_info['license']:
        card += f"**ğŸ“„ è®¸å¯è¯:** {repo_info['license']}\n\n"
    
    card += f"**ğŸ”— å¿«é€Ÿé“¾æ¥:** [è®¿é—®ä»“åº“]({repo_info['url']})"
    
    # æ·»åŠ å…¶ä»–è¯­è¨€
    if len(repo_info['languages']) > 1:
        other_langs = ', '.join([f'`{lang}`' for lang in repo_info['languages'][1:3]])
        card += f" | å…¶ä»–è¯­è¨€: {other_langs}"
    
    card += "\n\n---\n"
    return card
def generate_readme_content(repositories: List[Dict[str, Any]]) -> str:
    """
    ç”Ÿæˆå®Œæ•´çš„README.mdå†…å®¹
    """
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_repos = len(repositories)
    total_stars = sum(repo['stars'] for repo in repositories)
    total_forks = sum(repo['forks'] for repo in repositories)
    total_issues = sum(repo['open_issues'] for repo in repositories)
    
    # è·å–æ‰€æœ‰è¯­è¨€
    all_languages = []
    for repo in repositories:
        if repo['language'] and repo['language'] != 'å¤šç§è¯­è¨€':
            all_languages.append(repo['language'])
        all_languages.extend(repo['languages'])
    
    unique_languages = sorted(set(all_languages))
    
    # æŒ‰æ˜Ÿæ ‡æ•°æ’åº
    sorted_repos = sorted(repositories, key=lambda x: x['stars'], reverse=True)
    
    # ç”Ÿæˆæœ€è¿‘æ›´æ–°çš„ä»“åº“
    recent_repos = sorted(repositories, key=lambda x: x['updated_at'], reverse=True)[:3]
    
    # å¼€å§‹ç”ŸæˆMarkdown
    markdown = f"""# ğŸ§° {USERNAME}'s Toolbox
> ä¸ªäººå¼€å‘å·¥å…·ä¸é¡¹ç›®é›†åˆ | æœ€åæ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
## ğŸ“Š ä»ªè¡¨æ¿æ¦‚è§ˆ
| ç»Ÿè®¡é¡¹ | ç»“æœ | è¯´æ˜ |
|--------|------|------|
| ğŸ“ ä»“åº“æ€»æ•° | **{total_repos}** | æ”¶å½•çš„é¡¹ç›®æ•°é‡ |
| â­ ç´¯è®¡æ˜Ÿæ ‡ | **{total_stars}** | æ‰€æœ‰ä»“åº“æ˜Ÿæ ‡æ€»å’Œ |
| ğŸ´ ç´¯è®¡ Fork | **{total_forks}** | æ‰€æœ‰ä»“åº“Forkæ€»å’Œ |
| ğŸ”§ ä½¿ç”¨è¯­è¨€ | **{len(unique_languages)}** ç§ | {', '.join(unique_languages[:5])}{'...' if len(unique_languages) > 5 else ''} |
| ğŸ“… æœ€åæ›´æ–° | `{recent_repos[0]['updated_at'] if recent_repos else 'N/A'}` | {recent_repos[0]['name'] if recent_repos else ''} |
## ğŸ† çƒ­é—¨é¡¹ç›®
ä»¥ä¸‹æ˜¯æ ¹æ®æ˜Ÿæ ‡æ•°æ’åºçš„çƒ­é—¨é¡¹ç›®:
"""
    
    # æ·»åŠ ä»“åº“å¡ç‰‡
    for i, repo in enumerate(sorted_repos, 1):
        markdown += generate_repository_card(repo)
    
    # æ·»åŠ æœ€è¿‘æ›´æ–°éƒ¨åˆ†
    markdown += f"""
## ğŸ”„ æœ€è¿‘æ›´æ–°
| ä»“åº“ | æ›´æ–°æ—¥æœŸ | æ˜Ÿæ ‡æ•° | çŠ¶æ€ |
|------|----------|--------|------|
"""
    for repo in recent_repos:
        status = "ğŸŸ¢ æ´»è·ƒ"  # é»˜è®¤çŠ¶æ€
        try:
            if repo['updated_at']:  # ç¡®ä¿æ—¥æœŸä¸ä¸ºç©º
                # å¢åŠ æ—¥æœŸæ ¼å¼è§£æä¿æŠ¤
                date_obj = datetime.strptime(repo['updated_at'], '%Y-%m-%d')
                days_ago = (datetime.now() - date_obj).days
                if days_ago < 30:
                    status = "ğŸŸ¢ æ´»è·ƒ"
                elif days_ago < 90:
                    status = "ğŸŸ¡ ä¸€èˆ¬"
                else:
                    status = "ğŸ”´ åœæ»"
        except (ValueError, TypeError):
            # å¦‚æœæ—¥æœŸè§£æå¤±è´¥ï¼ˆä¾‹å¦‚æ ¼å¼ä¸å¯¹æˆ–ä¸ºç©ºï¼‰ï¼Œä¿æŒé»˜è®¤çŠ¶æ€
            pass
        
        markdown += f"| [{repo['name']}]({repo['url']}) | {repo['updated_at']} | â­ {repo['stars']} | {status} |\n"
    
    # æ·»åŠ æŠ€æœ¯æ ˆåˆ†æï¼ˆæ­¤å¤„ä½¿ç”¨ ~~~ é¿å…åµŒå¥— ``` å¯¼è‡´çš„æ˜¾ç¤ºé—®é¢˜ï¼‰
    markdown += """
## ğŸ”§ æŠ€æœ¯æ ˆåˆ†æ
### ä¸»è¦ç¼–ç¨‹è¯­è¨€åˆ†å¸ƒ
~~~
"""
    
    # ç®€å•çš„è¯­è¨€ç»Ÿè®¡
    lang_count = {}
    for repo in repositories:
        lang = repo['language']
        if lang and lang != 'å¤šç§è¯­è¨€':
            lang_count[lang] = lang_count.get(lang, 0) + 1
    
    for lang, count in sorted(lang_count.items(), key=lambda x: x[1], reverse=True):
        bar = 'â–ˆ' * count
        markdown += f"{lang:<15} {bar} ({count})\n"
    
    markdown += """~~~
### é¡¹ç›®ç‰¹æ€§ç»Ÿè®¡
- ğŸ“š å¸¦Wikiçš„é¡¹ç›®: {}/{}
- ğŸŒ å¯ç”¨Pagesçš„é¡¹ç›®: {}/{}
- ğŸ·ï¸ å¹³å‡æ ‡ç­¾æ•°: {:.1f} ä¸ª/é¡¹ç›®
- ğŸ“„ æœ‰è®¸å¯è¯çš„é¡¹ç›®: {}/{}
""".format(
        sum(1 for r in repositories if r['has_wiki']), total_repos,
        sum(1 for r in repositories if r['has_pages']), total_repos,
        sum(len(r['topics']) for r in repositories) / total_repos if total_repos > 0 else 0,
        sum(1 for r in repositories if r['license']), total_repos
    )
    
    # æ·»åŠ ä½¿ç”¨è¯´æ˜
    markdown += f"""
## ğŸš€ ä½¿ç”¨è¯´æ˜
### æ‰‹åŠ¨æ›´æ–°
è¦æ‰‹åŠ¨æ›´æ–°æ­¤é¡µé¢ï¼Œåœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ:
~~~bash
# ç¡®ä¿å·²å®‰è£…ä¾èµ–
pip install requests python-dotenv
# è¿è¡Œç”Ÿæˆè„šæœ¬
python generate_auto_descriptions.py
~~~
### è‡ªåŠ¨æ›´æ–°
æ­¤é¡µé¢é€šè¿‡GitHub Actionsè‡ªåŠ¨æ›´æ–°ï¼Œæ¯å¤©è¿è¡Œä¸€æ¬¡ã€‚
### æ·»åŠ æ–°ä»“åº“
è¦æ·»åŠ æ–°ä»“åº“åˆ°æ­¤å·¥å…·ç®±ï¼Œè¯·ä¿®æ”¹ `generate_auto_descriptions.py` æ–‡ä»¶ä¸­çš„ `REPO_LIST`ã€‚
## ğŸ“ é¡¹ç›®ç»“æ„
~~~
Toolbox/
â”œâ”€â”€ generate_auto_descriptions.py   # æœ¬è„šæœ¬
â”œâ”€â”€ README.md                       # æœ¬æ–‡ä»¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ tools_index.json                # JSONæ ¼å¼ç´¢å¼•
â”œâ”€â”€ .env                            # ç¯å¢ƒå˜é‡ï¼ˆæœ¬åœ°ï¼‰
â”œâ”€â”€ .github/workflows/              # GitHub Actions
â”œâ”€â”€ scripts/                        # è¾…åŠ©è„šæœ¬
â””â”€â”€ tools/                          # å­æ¨¡å—å­˜æ”¾å¤„
~~~
## ğŸ¤ è´¡çŒ®ä¸åé¦ˆ
è¿™ä¸ªå·¥å…·ç®±æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ã€‚å¦‚æœä½ å‘ç°ä»»ä½•é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·:
1. æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„GitHubä»¤ç‰Œæ˜¯å¦æ­£ç¡®
2. ç¡®ä¿è¦åˆ†æçš„ä»“åº“æ˜¯å…¬å¼€çš„
3. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
---
*âœ¨ æ­¤é¡µé¢ç”±è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*[æŸ¥çœ‹ç”Ÿæˆè„šæœ¬](generate_auto_descriptions.py) | [æŠ¥å‘Šé—®é¢˜](https://github.com/{USERNAME}/Toolbox/issues)*
"""
    
    return markdown


"""åˆå§‹åŒ–ç¯å¢ƒï¼šåˆ›å»ºç¼“å­˜ç›®å½•ã€éªŒè¯ä»¤ç‰Œ"""
# 1. ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
cache_dir = "api_cache"
if not os.path.exists(cache_dir):
    os.makedirs(cache_dir, exist_ok=True)
    print(f"ğŸ“ åˆ›å»ºç¼“å­˜ç›®å½•: {cache_dir}")

# 2. éªŒè¯ä»¤ç‰ŒåŸºæœ¬æ ¼å¼ï¼ˆç®€å•æ£€æŸ¥ï¼‰
token = os.getenv('GITHUB_TOKEN')
if not token or len(token) < 20:
    print("âŒ é”™è¯¯ï¼šGITHUB_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æ ¼å¼æ— æ•ˆã€‚")
    print("è¯·ç¡®ä¿å·²åœ¨GitHubä»“åº“çš„Secretsä¸­æ­£ç¡®è®¾ç½® PAT_TOKEN æˆ– GITHUB_TOKENã€‚")
    sys.exit(1)
# ========== ä¸»ç¨‹åº ==========
def main():
    """
    ä¸»å‡½æ•°ï¼šåè°ƒæ•´ä¸ªåˆ†æè¿‡ç¨‹
    """
    print("=" * 60)
    print(f"ğŸ§° {USERNAME}'s Toolbox ç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"ğŸ“‹ ç›®æ ‡ä»“åº“ ({len(REPO_LIST)} ä¸ª): {', '.join(REPO_LIST)}")
    print("-" * 60)
    
    # åˆ†ææ‰€æœ‰ä»“åº“
    all_repositories = []
    successful_repos = 0
    
    for repo_name in REPO_LIST:
        repo_info = analyze_repository(repo_name)
        if repo_info:
            all_repositories.append(repo_info)
            successful_repos += 1
        else:
            print(f"  âŒ è·³è¿‡ä»“åº“: {repo_name}")
    
    print("-" * 60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸåˆ†æçš„ä»“åº“
    if successful_repos == 0:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•ä»“åº“ã€‚")
        print("å¯èƒ½çš„åŸå› :")
        print("  1. GitHubä»¤ç‰Œæ— æ•ˆæˆ–æƒé™ä¸è¶³")
        print("  2. ä»“åº“ä¸å­˜åœ¨æˆ–ä¸æ˜¯å…¬å¼€ä»“åº“")
        print("  3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("  4. APIé€Ÿç‡é™åˆ¶")
        sys.exit(1)
    
    # ç”ŸæˆREADME
    print("ğŸ“ ç”ŸæˆREADME.mdæ–‡ä»¶...")
    readme_content = generate_readme_content(all_repositories)
    
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
    
    # ç”ŸæˆJSONç´¢å¼•
    print("ğŸ“Š ç”ŸæˆJSONç´¢å¼•æ–‡ä»¶...")
    json_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "total_repositories": successful_repos,
            "username": USERNAME,
            "toolbox_version": "1.0.0"
        },
        "statistics": {
            "total_stars": sum(r['stars'] for r in all_repositories),
            "total_forks": sum(r['forks'] for r in all_repositories),
            "total_issues": sum(r['open_issues'] for r in all_repositories),
            "languages": sorted(set(r['language'] for r in all_repositories if r['language']))
        },
        "repositories": [
            {
                "name": repo['name'],
                "url": repo['url'],
                "description": repo['final_description'],
                "stars": repo['stars'],
                "forks": repo['forks'],
                "language": repo['language'],
                "updated_at": repo['updated_at'],
                "topics": repo['topics'],
                "has_wiki": repo['has_wiki'],
                "license": repo['license']
            }
            for repo in all_repositories
        ]
    }
    
    with open("tools_index.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
    
    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    print("-" * 60)
    print("ğŸ‰ ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print(f"âœ… æˆåŠŸåˆ†æ: {successful_repos}/{len(REPO_LIST)} ä¸ªä»“åº“")
    print(f"â­ æ€»æ˜Ÿæ ‡æ•°: {sum(r['stars'] for r in all_repositories)}")
    print(f"ğŸ´ æ€»Forkæ•°: {sum(r['forks'] for r in all_repositories)}")
    print(f"ğŸ”§ æ¶‰åŠè¯­è¨€: {len(set(r['language'] for r in all_repositories))} ç§")
    print("")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  â€¢ README.md ({len(readme_content)} å­—ç¬¦)")
    print(f"  â€¢ tools_index.json (JSONæ ¼å¼ç´¢å¼•)")
    print("")
    print("ğŸš€ ä¸‹ä¸€æ­¥:")
    print("  1. æ£€æŸ¥ README.md æ–‡ä»¶å†…å®¹")
    print("  2. æäº¤æ›´æ”¹åˆ°GitHub: git add . && git commit -m 'æ›´æ–°å·¥å…·ç®±'")
    print("  3. æ¨é€: git push origin main")
    print("=" * 60)
# ========== è„šæœ¬å…¥å£ ==========
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œã€‚")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("é”™è¯¯ç±»å‹:", type(e).__name__)
        import traceback
        traceback.print_exc()
        sys.exit(1)